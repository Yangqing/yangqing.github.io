<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/papers/icml13.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>On Compact Codes for Spatially Pooled Features</strong><br />
      Y Jia, O Vinyals, T Darrell. ICML 2013. [PDF coming soon]
      <a href=http://arxiv.org/abs/1301.5348>[ICLR workshop version]</a>
    </p>
    <p class="abstract-text">
      We analyzed the connection between codebook size and accuracy with the Nystrom sampling theory, and showed how this leads to better pooling-aware codebook learning methods.
    </p> 
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/papers/nips12.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>Learning with Recursive Perceptual Representations</strong><br />
      O Vinyals, Y Jia, L Deng, T Darrell. NIPS 2012.
      <a href="assets/pdf/nips12_rsvm.pdf">[PDF]</a>
      <a href="assets/pdf/nips12_rsvm_poster.pdf">[Poster]</a>
    </p>
    <p class="abstract-text">
      We proposed R2SVM, an efficient algorithm to recursively learn deep nonlinear models by stacking linear SVMs with random projections.
    </p> 
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/papers/cvpr12.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>Beyond Spatial Pyramids: Receptive Field Learning for Pooled Image Features</strong><br />
      Y Jia, C Huang, T Darrell. CVPR 2012.
      <a href="assets/pdf/cvpr12_pooling.pdf">[PDF]</a>
      <a href="assets/pdf/cvpr12_pooling_slides.pdf">[Slides]</a>
      <a href="assets/pdf/cvpr12_pooling_poster.pdf">[Poster]</a>
    </p>
    <p class="abstract-text">
      We showed the suboptimality of spatial pyramids in feature pooling, and proposed an efficient way to learn task-dependent receptive fields for better pooled features.
    </p>
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/papers/uai12.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>Factorized Multi-modal Topic Model</strong><br />
      S Virtanen, Y Jia, A Klami, T Darrell. UAI 2012.
      <a href="assets/pdf/uai12_factorize.pdf">[PDF]</a>
      <a href="wikipedia.html">[Dataset]</a>
    </p>
    <p class="abstract-text">
      We factorized the information contained in corresponding image and text with a novel HDP-based topic model that automatically learns both shared and private topics.
    </p>
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/papers/nips11.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>Heavy-tailed Distances for Gradient Based Image Descriptors</strong><br />
      Y Jia, T Darrell. NIPS 2011.
      <a href="assets/pdf/nips11_gcl.pdf">[PDF]</a>
      <a href="assets/pdf/nips11_gcl_supp.pdf">[Supplementary Material]</a>
      <a href="assets/pdf/nips11_gcl_poster.pdf">[Poster]</a>
    </p>
    <p class="abstract-text">
      We examined the heavy-tailed noise distribution of gradient-based image descriptors, and proposed a new distance metric that yields higher feature matching performances.
    </p>
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/papers/iccv11.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>Learning Cross-modality Similarity for Multinomial Data</strong><br />
      Y Jia, M Salzmann, T Darrell. ICCV 2011
      <a href="assets/pdf/iccv11_mm.pdf">[PDF]</a>
      <a href="assets/pdf/iccv11_mm_poster.pdf">[Poster]</a>
      <a href="wikipedia.html">[Dataset]</a>
    </p>
    <p class="abstract-text">
      We propose a novel approach based on topic models and the Markov random field to capture the semantic relationships between documents from multiple modalities. 
    </p>
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/papers/iccv11-b3do.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>A Category-level 3-D Database: Putting the Kinect to Work</strong><br />
      A Janoch, S Karayev, Y Jia, J Barron, M Fritz, K Saenko, T Darrell. ICCV-CDC4CV workshop 2011
      <a href="assets/pdf/iccv11_kinect.pdf">[PDF]</a>
      <a href="http://kinectdata.com/">[Dataset]</a>
    </p>
    <p class="abstract-text">
      We presented a dataset of color and depth image pairs collected from the Kinect sensor, gathered in real domestic and ofÔ¨Åce environments, for research on object-level recognition with multimodal sensor input.
    </p>
  </div>
</div>